{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunja\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.layers import Activation, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape((x_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = to_categorical(y_train, num_classes=10, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = to_categorical(y_test, num_classes = 10, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-227d7f6c6ced>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# print(y_test[:5, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# print(y_train[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape=(784, ), kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, kernel_initializer = 'he_normal'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KerasClassifier(build_fn = mlp_model, epochs = 100, validation_split = 0.3)\n",
    "model2 = KerasClassifier(build_fn = mlp_model, epochs = 100, validation_split = 0.3)\n",
    "model3 = KerasClassifier(build_fn = mlp_model, epochs = 100, validation_split = 0.3)\n",
    "model4 = KerasClassifier(build_fn = mlp_model, epochs = 100, validation_split = 0.3)\n",
    "model5 = KerasClassifier(build_fn = mlp_model, epochs = 100, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = VotingClassifier(estimators = [('model1', model1), ('model2', model2)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 21s 507us/step - loss: 0.8740 - acc: 0.7241 - val_loss: 0.2714 - val_acc: 0.9229\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 19s 458us/step - loss: 0.4993 - acc: 0.8550 - val_loss: 0.2099 - val_acc: 0.9395\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 20s 467us/step - loss: 0.4176 - acc: 0.8784 - val_loss: 0.1827 - val_acc: 0.9474\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 22s 524us/step - loss: 0.3732 - acc: 0.8940 - val_loss: 0.1743 - val_acc: 0.9494\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 23s 557us/step - loss: 0.3394 - acc: 0.9033 - val_loss: 0.1612 - val_acc: 0.9527\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 22s 525us/step - loss: 0.3081 - acc: 0.9112 - val_loss: 0.1490 - val_acc: 0.9552\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.3003 - acc: 0.9145 - val_loss: 0.1419 - val_acc: 0.9589\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 22s 525us/step - loss: 0.2878 - acc: 0.9156 - val_loss: 0.1362 - val_acc: 0.9600\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 22s 528us/step - loss: 0.2688 - acc: 0.9222 - val_loss: 0.1319 - val_acc: 0.9618\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 22s 515us/step - loss: 0.2681 - acc: 0.9220 - val_loss: 0.1285 - val_acc: 0.9624\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 22s 520us/step - loss: 0.2610 - acc: 0.9240 - val_loss: 0.1263 - val_acc: 0.9630\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 22s 515us/step - loss: 0.2516 - acc: 0.9286 - val_loss: 0.1245 - val_acc: 0.9630\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 22s 515us/step - loss: 0.2454 - acc: 0.9298 - val_loss: 0.1240 - val_acc: 0.9637\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 22s 526us/step - loss: 0.2372 - acc: 0.9329 - val_loss: 0.1216 - val_acc: 0.9658\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 22s 521us/step - loss: 0.2378 - acc: 0.9304 - val_loss: 0.1210 - val_acc: 0.9644\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.2280 - acc: 0.9333 - val_loss: 0.1228 - val_acc: 0.9644\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.2226 - acc: 0.9357 - val_loss: 0.1162 - val_acc: 0.9667s: 0.2232 - - ETA: 0s - loss: 0.2230 - acc: \n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 22s 526us/step - loss: 0.2199 - acc: 0.9367 - val_loss: 0.1130 - val_acc: 0.9672\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 22s 520us/step - loss: 0.2145 - acc: 0.9381 - val_loss: 0.1140 - val_acc: 0.9669\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 22s 532us/step - loss: 0.2164 - acc: 0.9378 - val_loss: 0.1114 - val_acc: 0.9677\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 22s 522us/step - loss: 0.2102 - acc: 0.9403 - val_loss: 0.1127 - val_acc: 0.9668\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 22s 520us/step - loss: 0.2066 - acc: 0.9400 - val_loss: 0.1192 - val_acc: 0.9662\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 22s 528us/step - loss: 0.2068 - acc: 0.9397 - val_loss: 0.1130 - val_acc: 0.9671\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 22s 522us/step - loss: 0.2062 - acc: 0.9401 - val_loss: 0.1101 - val_acc: 0.9674\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 22s 526us/step - loss: 0.1987 - acc: 0.9426 - val_loss: 0.1109 - val_acc: 0.9684\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 22s 521us/step - loss: 0.1975 - acc: 0.9429 - val_loss: 0.1090 - val_acc: 0.9697\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 22s 526us/step - loss: 0.1997 - acc: 0.9403 - val_loss: 0.1056 - val_acc: 0.9696\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 22s 524us/step - loss: 0.1944 - acc: 0.9434 - val_loss: 0.1063 - val_acc: 0.9695\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 22s 521us/step - loss: 0.1919 - acc: 0.9450 - val_loss: 0.1063 - val_acc: 0.9697\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 22s 523us/step - loss: 0.1870 - acc: 0.9453 - val_loss: 0.1087 - val_acc: 0.9693\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 24s 573us/step - loss: 0.1849 - acc: 0.9461 - val_loss: 0.1116 - val_acc: 0.9682\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 22s 531us/step - loss: 0.1886 - acc: 0.9451 - val_loss: 0.1119 - val_acc: 0.9676\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 22s 525us/step - loss: 0.1841 - acc: 0.9456 - val_loss: 0.1103 - val_acc: 0.9686\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 22s 521us/step - loss: 0.1896 - acc: 0.9451 - val_loss: 0.1084 - val_acc: 0.9683\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 23s 550us/step - loss: 0.1818 - acc: 0.9465 - val_loss: 0.1065 - val_acc: 0.9701\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 22s 527us/step - loss: 0.1810 - acc: 0.9473 - val_loss: 0.1084 - val_acc: 0.9689\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.1803 - acc: 0.9476 - val_loss: 0.1053 - val_acc: 0.9693\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 22s 522us/step - loss: 0.1792 - acc: 0.9487 - val_loss: 0.1072 - val_acc: 0.9696\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.1769 - acc: 0.9490 - val_loss: 0.1071 - val_acc: 0.9694\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 22s 519us/step - loss: 0.1778 - acc: 0.9476 - val_loss: 0.1075 - val_acc: 0.9690\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.1753 - acc: 0.9495 - val_loss: 0.1050 - val_acc: 0.9698\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 22s 521us/step - loss: 0.1725 - acc: 0.9490 - val_loss: 0.1079 - val_acc: 0.9693\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.1733 - acc: 0.9495 - val_loss: 0.1072 - val_acc: 0.9689\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 22s 519us/step - loss: 0.1745 - acc: 0.9495 - val_loss: 0.1040 - val_acc: 0.9700\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 22s 520us/step - loss: 0.1712 - acc: 0.9491 - val_loss: 0.1049 - val_acc: 0.9693\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 22s 519us/step - loss: 0.1672 - acc: 0.9515 - val_loss: 0.1052 - val_acc: 0.9694\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 22s 529us/step - loss: 0.1720 - acc: 0.9485 - val_loss: 0.1049 - val_acc: 0.9698\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.1674 - acc: 0.9503 - val_loss: 0.1048 - val_acc: 0.9710\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.1705 - acc: 0.9505 - val_loss: 0.1030 - val_acc: 0.9720\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 22s 520us/step - loss: 0.1694 - acc: 0.9507 - val_loss: 0.1052 - val_acc: 0.9692\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.1692 - acc: 0.9502 - val_loss: 0.1037 - val_acc: 0.9706\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.1652 - acc: 0.9515 - val_loss: 0.1031 - val_acc: 0.9705\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.1637 - acc: 0.9503 - val_loss: 0.1043 - val_acc: 0.9708\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.1577 - acc: 0.9541 - val_loss: 0.1049 - val_acc: 0.9701\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 22s 516us/step - loss: 0.1577 - acc: 0.9534 - val_loss: 0.1011 - val_acc: 0.9708\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.1633 - acc: 0.9523 - val_loss: 0.1058 - val_acc: 0.9698\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 22s 517us/step - loss: 0.1614 - acc: 0.9518 - val_loss: 0.1045 - val_acc: 0.9694\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 21s 505us/step - loss: 0.1619 - acc: 0.9518 - val_loss: 0.1045 - val_acc: 0.9706\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 21s 505us/step - loss: 0.1584 - acc: 0.9538 - val_loss: 0.1054 - val_acc: 0.9696\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 20s 473us/step - loss: 0.1555 - acc: 0.9540 - val_loss: 0.1039 - val_acc: 0.9708\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 20s 474us/step - loss: 0.1548 - acc: 0.9534 - val_loss: 0.1056 - val_acc: 0.9696\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 20s 469us/step - loss: 0.1568 - acc: 0.9541 - val_loss: 0.1085 - val_acc: 0.9694\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 20s 470us/step - loss: 0.1552 - acc: 0.9545 - val_loss: 0.1064 - val_acc: 0.9691\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 20s 470us/step - loss: 0.1530 - acc: 0.9547 - val_loss: 0.1049 - val_acc: 0.9697\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 20s 468us/step - loss: 0.1548 - acc: 0.9541 - val_loss: 0.1037 - val_acc: 0.9700\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 20s 471us/step - loss: 0.1538 - acc: 0.9560 - val_loss: 0.1051 - val_acc: 0.9699\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 20s 469us/step - loss: 0.1556 - acc: 0.9546 - val_loss: 0.1071 - val_acc: 0.9704\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 20s 468us/step - loss: 0.1556 - acc: 0.9542 - val_loss: 0.1051 - val_acc: 0.9703\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 20s 470us/step - loss: 0.1516 - acc: 0.9559 - val_loss: 0.1038 - val_acc: 0.9693\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 20s 471us/step - loss: 0.1508 - acc: 0.9545 - val_loss: 0.1058 - val_acc: 0.9700\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 20s 470us/step - loss: 0.1494 - acc: 0.9545 - val_loss: 0.1046 - val_acc: 0.9693\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 20s 468us/step - loss: 0.1510 - acc: 0.9551 - val_loss: 0.1017 - val_acc: 0.9714\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 20s 470us/step - loss: 0.1494 - acc: 0.9559 - val_loss: 0.1020 - val_acc: 0.9717\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 20s 468us/step - loss: 0.1519 - acc: 0.9562 - val_loss: 0.1058 - val_acc: 0.9692\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 20s 470us/step - loss: 0.1491 - acc: 0.9559 - val_loss: 0.1062 - val_acc: 0.9695\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 20s 479us/step - loss: 0.1527 - acc: 0.9560 - val_loss: 0.1019 - val_acc: 0.9716\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 20s 472us/step - loss: 0.1454 - acc: 0.9572 - val_loss: 0.1030 - val_acc: 0.9705\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 20s 471us/step - loss: 0.1463 - acc: 0.9562 - val_loss: 0.1036 - val_acc: 0.9703\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 20s 468us/step - loss: 0.1498 - acc: 0.9568 - val_loss: 0.1057 - val_acc: 0.9697\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 22s 512us/step - loss: 0.1481 - acc: 0.9566 - val_loss: 0.1012 - val_acc: 0.9709\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 22s 513us/step - loss: 0.1467 - acc: 0.9565 - val_loss: 0.1032 - val_acc: 0.9696\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 21s 506us/step - loss: 0.1420 - acc: 0.9575 - val_loss: 0.1015 - val_acc: 0.9709\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 20s 467us/step - loss: 0.1432 - acc: 0.9567 - val_loss: 0.1038 - val_acc: 0.9716\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 18s 438us/step - loss: 0.1450 - acc: 0.9573 - val_loss: 0.1033 - val_acc: 0.9702\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 22s 523us/step - loss: 0.1471 - acc: 0.9565 - val_loss: 0.0987 - val_acc: 0.9712\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 23s 555us/step - loss: 0.1411 - acc: 0.9575 - val_loss: 0.1019 - val_acc: 0.9708\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 23s 540us/step - loss: 0.1426 - acc: 0.9589 - val_loss: 0.1051 - val_acc: 0.9702\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 22s 525us/step - loss: 0.1444 - acc: 0.9577 - val_loss: 0.0998 - val_acc: 0.9717\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 23s 548us/step - loss: 0.1423 - acc: 0.9579 - val_loss: 0.1017 - val_acc: 0.9703\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 20s 477us/step - loss: 0.1470 - acc: 0.9563 - val_loss: 0.1037 - val_acc: 0.9704\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 22s 521us/step - loss: 0.1438 - acc: 0.9583 - val_loss: 0.1013 - val_acc: 0.9704\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.1488 - acc: 0.9553 - val_loss: 0.1006 - val_acc: 0.9713\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 24s 570us/step - loss: 0.1440 - acc: 0.9582 - val_loss: 0.1015 - val_acc: 0.9704\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 25s 587us/step - loss: 0.1393 - acc: 0.9589 - val_loss: 0.1035 - val_acc: 0.9704\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 24s 566us/step - loss: 0.1457 - acc: 0.9568 - val_loss: 0.1022 - val_acc: 0.9713\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 25s 585us/step - loss: 0.1419 - acc: 0.9588 - val_loss: 0.1046 - val_acc: 0.9697\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 22s 525us/step - loss: 0.1396 - acc: 0.9579 - val_loss: 0.1041 - val_acc: 0.9706\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 23s 537us/step - loss: 0.1402 - acc: 0.9599 - val_loss: 0.1003 - val_acc: 0.9714\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 23s 546us/step - loss: 0.1394 - acc: 0.9588 - val_loss: 0.1041 - val_acc: 0.9709\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 22s 534us/step - loss: 0.1439 - acc: 0.9574 - val_loss: 0.1038 - val_acc: 0.9707\n",
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 26s 607us/step - loss: 0.8788 - acc: 0.7292 - val_loss: 0.2528 - val_acc: 0.9261\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 20s 488us/step - loss: 0.4834 - acc: 0.8613 - val_loss: 0.2028 - val_acc: 0.9391\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 21s 499us/step - loss: 0.4014 - acc: 0.8858 - val_loss: 0.1709 - val_acc: 0.9504\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 20s 479us/step - loss: 0.3644 - acc: 0.8967 - val_loss: 0.1523 - val_acc: 0.9556\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 19s 464us/step - loss: 0.3281 - acc: 0.9054 - val_loss: 0.1470 - val_acc: 0.9576\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 20s 481us/step - loss: 0.3063 - acc: 0.9137 - val_loss: 0.1378 - val_acc: 0.9594\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 22s 535us/step - loss: 0.2928 - acc: 0.9169 - val_loss: 0.1326 - val_acc: 0.9618\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 23s 543us/step - loss: 0.2768 - acc: 0.9216 - val_loss: 0.1238 - val_acc: 0.9639\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 24s 573us/step - loss: 0.2690 - acc: 0.9229 - val_loss: 0.1183 - val_acc: 0.9646\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 23s 547us/step - loss: 0.2538 - acc: 0.9272 - val_loss: 0.1202 - val_acc: 0.9641\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 23s 536us/step - loss: 0.2505 - acc: 0.9274 - val_loss: 0.1200 - val_acc: 0.9636ss: 0.2502 - \n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 21s 501us/step - loss: 0.2417 - acc: 0.9307 - val_loss: 0.1185 - val_acc: 0.9648\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 24s 575us/step - loss: 0.2330 - acc: 0.9341 - val_loss: 0.1106 - val_acc: 0.9678\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 23s 543us/step - loss: 0.2308 - acc: 0.9346 - val_loss: 0.1082 - val_acc: 0.9680\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 23s 538us/step - loss: 0.2265 - acc: 0.9345 - val_loss: 0.1113 - val_acc: 0.9664\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 24s 563us/step - loss: 0.2204 - acc: 0.9366 - val_loss: 0.1126 - val_acc: 0.9672\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 22s 529us/step - loss: 0.2143 - acc: 0.9383 - val_loss: 0.1052 - val_acc: 0.9689\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 22s 533us/step - loss: 0.2118 - acc: 0.9389 - val_loss: 0.1080 - val_acc: 0.9676\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 24s 572us/step - loss: 0.2096 - acc: 0.9406 - val_loss: 0.1064 - val_acc: 0.9690: 0.94\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 23s 540us/step - loss: 0.2047 - acc: 0.9401 - val_loss: 0.1044 - val_acc: 0.9683\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 23s 547us/step - loss: 0.2078 - acc: 0.9399 - val_loss: 0.1043 - val_acc: 0.96879s - loss: 0 - ETA: 9s - loss: 0.2007 - acc: - ETA: 8s - lo - E\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 20s 471us/step - loss: 0.2001 - acc: 0.9415 - val_loss: 0.1047 - val_acc: 0.9689\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 19s 451us/step - loss: 0.2014 - acc: 0.9413 - val_loss: 0.1028 - val_acc: 0.9689\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 20s 472us/step - loss: 0.1950 - acc: 0.9447 - val_loss: 0.1036 - val_acc: 0.9686\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 20s 486us/step - loss: 0.1952 - acc: 0.9441 - val_loss: 0.1016 - val_acc: 0.9694\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 20s 477us/step - loss: 0.1964 - acc: 0.9435 - val_loss: 0.1023 - val_acc: 0.9691\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 19s 452us/step - loss: 0.1957 - acc: 0.9435 - val_loss: 0.1020 - val_acc: 0.9699\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1897 - acc: 0.9457 - val_loss: 0.1041 - val_acc: 0.9692\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 19s 455us/step - loss: 0.1888 - acc: 0.9451 - val_loss: 0.1026 - val_acc: 0.9692\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 19s 448us/step - loss: 0.1850 - acc: 0.9477 - val_loss: 0.1031 - val_acc: 0.9707\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 19s 452us/step - loss: 0.1787 - acc: 0.9475 - val_loss: 0.1003 - val_acc: 0.9702\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 19s 449us/step - loss: 0.1832 - acc: 0.9461 - val_loss: 0.0960 - val_acc: 0.9717\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 19s 451us/step - loss: 0.1780 - acc: 0.9480 - val_loss: 0.0979 - val_acc: 0.9713\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 19s 447us/step - loss: 0.1812 - acc: 0.9486 - val_loss: 0.1006 - val_acc: 0.9697\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 19s 457us/step - loss: 0.1775 - acc: 0.9490 - val_loss: 0.0968 - val_acc: 0.9711\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 19s 449us/step - loss: 0.1731 - acc: 0.9505 - val_loss: 0.0984 - val_acc: 0.9712\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 19s 449us/step - loss: 0.1764 - acc: 0.9482 - val_loss: 0.0982 - val_acc: 0.9698\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 19s 449us/step - loss: 0.1734 - acc: 0.9495 - val_loss: 0.0995 - val_acc: 0.9698\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 19s 460us/step - loss: 0.1729 - acc: 0.9502 - val_loss: 0.1012 - val_acc: 0.9699\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 19s 447us/step - loss: 0.1739 - acc: 0.9501 - val_loss: 0.0971 - val_acc: 0.9721\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 19s 447us/step - loss: 0.1742 - acc: 0.9494 - val_loss: 0.0977 - val_acc: 0.9699\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 19s 450us/step - loss: 0.1728 - acc: 0.9509 - val_loss: 0.0965 - val_acc: 0.9708\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 19s 450us/step - loss: 0.1695 - acc: 0.9488 - val_loss: 0.0987 - val_acc: 0.9709\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 19s 450us/step - loss: 0.1727 - acc: 0.9500 - val_loss: 0.1004 - val_acc: 0.9701\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 20s 475us/step - loss: 0.1661 - acc: 0.9523 - val_loss: 0.0989 - val_acc: 0.9708\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 19s 449us/step - loss: 0.1685 - acc: 0.9507 - val_loss: 0.0959 - val_acc: 0.9709\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 19s 446us/step - loss: 0.1612 - acc: 0.9533 - val_loss: 0.0958 - val_acc: 0.9713\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 19s 446us/step - loss: 0.1646 - acc: 0.9526 - val_loss: 0.0981 - val_acc: 0.9711\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 23s 539us/step - loss: 0.1652 - acc: 0.9515 - val_loss: 0.0972 - val_acc: 0.9716\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 24s 575us/step - loss: 0.1615 - acc: 0.9539 - val_loss: 0.0957 - val_acc: 0.9720\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 24s 571us/step - loss: 0.1696 - acc: 0.9507 - val_loss: 0.0961 - val_acc: 0.9714\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 22s 518us/step - loss: 0.1604 - acc: 0.9518 - val_loss: 0.0992 - val_acc: 0.9709\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 22s 516us/step - loss: 0.1553 - acc: 0.9545 - val_loss: 0.1007 - val_acc: 0.9705\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 21s 504us/step - loss: 0.1602 - acc: 0.9538 - val_loss: 0.0991 - val_acc: 0.9707\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 20s 466us/step - loss: 0.1623 - acc: 0.9528 - val_loss: 0.0963 - val_acc: 0.9714\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 19s 454us/step - loss: 0.1587 - acc: 0.9537 - val_loss: 0.0949 - val_acc: 0.9706\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 19s 455us/step - loss: 0.1590 - acc: 0.9530 - val_loss: 0.0957 - val_acc: 0.9718\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 19s 454us/step - loss: 0.1579 - acc: 0.9542 - val_loss: 0.0971 - val_acc: 0.9710\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 19s 454us/step - loss: 0.1562 - acc: 0.9550 - val_loss: 0.0927 - val_acc: 0.9725\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 20s 469us/step - loss: 0.1558 - acc: 0.9549 - val_loss: 0.0945 - val_acc: 0.9719\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 19s 457us/step - loss: 0.1605 - acc: 0.9539 - val_loss: 0.0962 - val_acc: 0.9716\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 20s 482us/step - loss: 0.1587 - acc: 0.9533 - val_loss: 0.0934 - val_acc: 0.9716\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1514 - acc: 0.9565 - val_loss: 0.0956 - val_acc: 0.9713\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 20s 467us/step - loss: 0.1552 - acc: 0.9547 - val_loss: 0.0955 - val_acc: 0.9712\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 19s 456us/step - loss: 0.1563 - acc: 0.9548 - val_loss: 0.0965 - val_acc: 0.9706\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 19s 456us/step - loss: 0.1501 - acc: 0.9556 - val_loss: 0.0971 - val_acc: 0.9703\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 19s 451us/step - loss: 0.1555 - acc: 0.9543 - val_loss: 0.0984 - val_acc: 0.9707\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 19s 452us/step - loss: 0.1549 - acc: 0.9546 - val_loss: 0.0931 - val_acc: 0.9724\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1473 - acc: 0.9567 - val_loss: 0.0953 - val_acc: 0.9719\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1543 - acc: 0.9553 - val_loss: 0.0956 - val_acc: 0.9726\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1480 - acc: 0.9575 - val_loss: 0.0951 - val_acc: 0.9720\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1477 - acc: 0.9563 - val_loss: 0.0964 - val_acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 19s 454us/step - loss: 0.1510 - acc: 0.9565 - val_loss: 0.0973 - val_acc: 0.9705\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1489 - acc: 0.9562 - val_loss: 0.0958 - val_acc: 0.9717\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 19s 458us/step - loss: 0.1424 - acc: 0.9567 - val_loss: 0.0935 - val_acc: 0.9721\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 20s 473us/step - loss: 0.1528 - acc: 0.9547 - val_loss: 0.0942 - val_acc: 0.9726\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 19s 453us/step - loss: 0.1468 - acc: 0.9578 - val_loss: 0.0934 - val_acc: 0.9725\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 19s 451us/step - loss: 0.1474 - acc: 0.9570 - val_loss: 0.0930 - val_acc: 0.9722\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 19s 452us/step - loss: 0.1474 - acc: 0.9555 - val_loss: 0.0958 - val_acc: 0.9711\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 19s 450us/step - loss: 0.1494 - acc: 0.9561 - val_loss: 0.0939 - val_acc: 0.9719\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 19s 456us/step - loss: 0.1460 - acc: 0.9572 - val_loss: 0.0947 - val_acc: 0.9722\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 19s 457us/step - loss: 0.1437 - acc: 0.9572 - val_loss: 0.0944 - val_acc: 0.9720\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 20s 485us/step - loss: 0.1481 - acc: 0.9573 - val_loss: 0.0941 - val_acc: 0.9718\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 20s 468us/step - loss: 0.1471 - acc: 0.9572 - val_loss: 0.0974 - val_acc: 0.9713\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 19s 454us/step - loss: 0.1453 - acc: 0.9576 - val_loss: 0.0956 - val_acc: 0.9715\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 20s 476us/step - loss: 0.1417 - acc: 0.9584 - val_loss: 0.0928 - val_acc: 0.9729\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 21s 491us/step - loss: 0.1445 - acc: 0.9580 - val_loss: 0.0953 - val_acc: 0.9718\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 20s 472us/step - loss: 0.1429 - acc: 0.9578 - val_loss: 0.0941 - val_acc: 0.9725\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 22s 513us/step - loss: 0.1429 - acc: 0.9580 - val_loss: 0.0948 - val_acc: 0.9719\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 22s 521us/step - loss: 0.1357 - acc: 0.9596 - val_loss: 0.1000 - val_acc: 0.9715\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 22s 513us/step - loss: 0.1473 - acc: 0.9574 - val_loss: 0.0952 - val_acc: 0.9708 loss: 0.1463 - acc:\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 20s 470us/step - loss: 0.1451 - acc: 0.9576 - val_loss: 0.0917 - val_acc: 0.9731\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 19s 458us/step - loss: 0.1390 - acc: 0.9596 - val_loss: 0.0958 - val_acc: 0.9718\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 19s 457us/step - loss: 0.1406 - acc: 0.9593 - val_loss: 0.0951 - val_acc: 0.9719\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 20s 476us/step - loss: 0.1421 - acc: 0.9579 - val_loss: 0.0940 - val_acc: 0.9726\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 19s 460us/step - loss: 0.1372 - acc: 0.9588 - val_loss: 0.0977 - val_acc: 0.9709\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 20s 472us/step - loss: 0.1401 - acc: 0.9603 - val_loss: 0.0974 - val_acc: 0.9721\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 21s 510us/step - loss: 0.1402 - acc: 0.9591 - val_loss: 0.0965 - val_acc: 0.9711\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 21s 489us/step - loss: 0.1409 - acc: 0.9586 - val_loss: 0.0947 - val_acc: 0.9731\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 21s 497us/step - loss: 0.1395 - acc: 0.9581 - val_loss: 0.0948 - val_acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1', <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000024FAD171080>), ('model2', <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000024FAD171D30>)],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunja\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = ensemble_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9769\n"
     ]
    }
   ],
   "source": [
    "print('Acc:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
